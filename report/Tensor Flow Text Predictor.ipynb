{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Flow Text Prediction\n",
    "#### Authors: Alexandria Davis, Donald Dong\n",
    "## Introduction\n",
    "\n",
    "A popular problem in data science is predictive text. Whether it is used for type suggestion, making swipe keyboards more accurate, or simply out of fun, text prediction is a challenge most data scientists attack with a nerual net.\n",
    "\n",
    "This neural net is based off of [Karpathy's nerual net](https://gist.github.com/karpathy/d4dee566867f8291f086), however utilizes tensorflow to improve the net's speed, object oriented programming to make our code more readable. The neural nets are also able to save their progress mid training, which allows for easier testing and crash recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "alice_txt = '../data/alice.txt'\n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.WARN)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Temp import the source. Will be removed in the final report\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "# Import all the dependency here so we don't have to run everything\n",
    "from src.dataset import Batch\n",
    "from src.dataset import Dataset\n",
    "from src.text_generator import RNNTextGenerator\n",
    "from src.model_selector import ModelSelector\n",
    "from src.time_limit import time_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "To prepare our data for use by our neural net, we first needed to split it into groups of data that follow specific rules. To streamline the process, we used the `Dataset` class to store and manage our input data. This class was responsible for splitting the data into strings of the correct length and for turning them into one hot encoded arrays that the neural net could better understand. We stored this pre-prepared data in a `Batch` object, which has `inputs` and `targets` attributes for our model to use in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from src.dataset import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from src.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from test.dataset_test import test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch(alice_txt, 5, 100) # The test passes without any errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the RNN Text Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text generator itself is stored in the `RNNTextGenerator` class. Among other things, storing the generator in the class allows the session helps prevent accidental data loss.\n",
    "\n",
    "The class also internalizes the methods needed to save and restore the model as a file. This allows for long term storage and quick retreaval of a file, as well as increasing the ease of using the weights for a model with a different sized input.\n",
    "\n",
    "The text generator does not take batches when training, however, and needs to be fed the inputs and targets seperately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from src.text_generator import RNNTextGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and restore the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from test.text_generator_test import test_save_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_save_restore(4, 5, 10) # The test passes without any errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect tensorflow logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from test.text_generator_test import test_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_log(4, 10, '../tf_logs') # The test passes without any errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Here will be a screenshot from the tensorboard*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the RNN Text Generator\n",
    "A short amount of training provides us with a model that is capable of forming multiple words and a few phrases, but not much more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from test.alice_test import test_alice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some text! Start by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = test_alice(alice_txt, 'my favorite ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(15, 6), ncols=2)\n",
    "scores['accuracy'].plot(ax=axes[0], title='Accuracy')\n",
    "scores['loss'].plot(ax=axes[1], title='Loss')\n",
    "for ax in axes:\n",
    "    ax.set(xlabel='Steps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Model Selector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from src.model_selector import ModelSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from test.model_selector_test import test_model_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 25\n",
    "dataset = Dataset([alice_txt], seq_length)\n",
    "params = {\n",
    "    'rnn_cell': [\n",
    "        tf.nn.rnn_cell.BasicRNNCell,\n",
    "        tf.nn.rnn_cell.LSTMCell,\n",
    "        tf.nn.rnn_cell.GRUCell,\n",
    "    ],\n",
    "    'n_neurons': np.arange(1, 1000),\n",
    "    'activation': [\n",
    "        tf.nn.relu,\n",
    "        tf.nn.leaky_relu,\n",
    "        tf.nn.relu6,\n",
    "        tf.nn.crelu,\n",
    "        tf.nn.elu,\n",
    "        tf.nn.selu,\n",
    "        tf.nn.softplus,\n",
    "        tf.nn.softsign,\n",
    "        tf.nn.dropout,\n",
    "        tf.sigmoid,\n",
    "        tf.tanh,\n",
    "    ],\n",
    "    'output_keep_prob': np.linspace(0.5, 1, 100, endpoint=True),\n",
    "    'optimizer': [\n",
    "        tf.train.AdamOptimizer,\n",
    "        tf.train.GradientDescentOptimizer,\n",
    "    ],\n",
    "    'learning_rate': np.linspace(0, 1, 10000, endpoint=False),\n",
    "    'epoch': np.arange(5, 100),\n",
    "    'batch_size': np.arange(25, 100),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_selector(dataset, params, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We allow models to train for a restricted amount of time. This is useful for training multiple models over night, as they would not need to be manually stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from src.time_limit import time_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = ModelSelector(dataset, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in time_limit(hours=3):\n",
    "    selector.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.as_df().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = selector.best_model()\n",
    "start_seq = 'Alice is'\n",
    "print(start_seq, model.generate(\n",
    "    dataset,\n",
    "    start_seq,\n",
    "    100\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then continued to train the same model on our dataset to see how well our model learned when it continued to be fed data from its dataset. \n",
    "\n",
    "Every so many epochs, we paused training to test our model by generating our models scores and generating a sample text. This information is stored for comparison purpouses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in time_limit(hours=1):\n",
    "    model.fit(dataset)\n",
    "    start_seq = 'Alice is '\n",
    "    print(start_seq, model.generate(\n",
    "        dataset,\n",
    "        start_seq,\n",
    "        100\n",
    "    ))\n",
    "    print('-----------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
