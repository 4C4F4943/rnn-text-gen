{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_txt = '../data/alice.txt'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.WARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imports below are to allow models to train for a restricted amount of time. This is useful for training multiple models over night, as they would not need to be manually stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Temp import the source. Will be removed in the final reportc\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "To prepare our data for use by our neural net, we first needed to split it into groups of data that follow specific rules. To streamline the process, we used the `Dataset` class to store and manage our input data. This class was responsible for splitting the data into strings of the correct length and for turning them into one hot encoded arrays that the neural net could better understand. We stored this pre-prepared data in a `Batch` object, which has `inputs` and `targets` attributes for our model to use in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from src.dataset import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from src.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from test.dataset_test import test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch(alice_txt, 5, 100) # The test passes without any errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the RNN Text Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text generator itself is stored in the `RNNTextGenerator` class. Among other things, storing the generator in the class allows the session helps prevent accidental data loss.\n",
    "\n",
    "The class also internalizes the methods needed to save and restore the model as a file. This allows for long term storage and quick retreaval of a file, as well as increasing the ease of using the weights for a model with a different sized input.\n",
    "\n",
    "The text generator does not take batches when training, however, and needs to be fed the inputs and targets seperately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from src.text_generator import RNNTextGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and restore the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from test.text_generator_test import test_save_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_save_restore(4, 5, 10) # The test passes without any errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect tensorflow logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from test.text_generator_test import test_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_log(4, 10, '../tf_logs') # The test passes without any errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Here will be a screenshot from the tensorboard*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the RNN Text Generator\n",
    "A short amount of training provides us with a model that is capable of forming multiple words and a few phrases, but not much more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from test.alice_test import test_alice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some text! Start by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = test_alice(alice_txt, 'my favorite ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(15, 6), ncols=2)\n",
    "scores['accuracy'].plot(ax=axes[0], title='Accuracy')\n",
    "scores['loss'].plot(ax=axes[1], title='Loss')\n",
    "for ax in axes:\n",
    "    ax.set(xlabel='Steps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Model Selector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from src.model_selector import ModelSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The real code will be inserted here in the final report\n",
    "\"\"\"\n",
    "from test.model_selector_test import test_model_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 25\n",
    "dataset = Dataset([alice_txt], seq_length)\n",
    "params = {\n",
    "    'rnn_cell': [\n",
    "        tf.contrib.rnn.BasicRNNCell\n",
    "    ],\n",
    "    'n_neurons': np.arange(1, 1000),\n",
    "    'optimizer': [\n",
    "        tf.train.AdamOptimizer,\n",
    "    ],\n",
    "    'learning_rate': np.linspace(0, 1, 10000, endpoint=False),\n",
    "    'epoch': np.arange(5, 100),\n",
    "    'batch_size': np.arange(25, 100),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_selector(dataset, params, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the best model\n",
    "We then continued to train the same model on our dataset to see how well our model learned when it continued to be fed data from its dataset. \n",
    "\n",
    "Every so many epochs, we paused training to test our model by generating our models scores and generating a sample text. This information is stored for comparison purpouses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of date\n",
    "def train_test(\n",
    "    dataset,\n",
    "    learning_rate,\n",
    "    start_seed,\n",
    "    model_name = \"RNNTextGenerator\",\n",
    "    model_exists = True,\n",
    "    train_seq_length = 25,\n",
    "    epoch = 20,\n",
    "    time_limit = 10\n",
    "    ):\n",
    "    runs_for = timedelta(minutes=time_limit)\n",
    "    start_time = datetime.now()\n",
    "    while(runs_for > datetime.now() - start_time ):\n",
    "        #build model to train on\n",
    "        model = RNNTextGenerator(\n",
    "            train_seq_length,\n",
    "            dataset.vocab_size,\n",
    "            learning_rate=learning_rate,\n",
    "            name=model_name,\n",
    "        )\n",
    "        try:\n",
    "            #If a model exists, we will need to restore it before we begin training.\n",
    "            model.restore()\n",
    "        except:\n",
    "            #If no model already exists, we can afford to ignore this error.\n",
    "            pass\n",
    "        #train\n",
    "        for _ in range(epoch):\n",
    "            for batch in dataset.batch(batch_size):\n",
    "                model.fit(batch.inputs, batch.targets)\n",
    "        model.save()\n",
    "        model_exists = True\n",
    "        #Build model to sample with\n",
    "        model = RNNTextGenerator(\n",
    "            len(start_seed),\n",
    "        dataset.vocab_size,\n",
    "            name=model_name,\n",
    "        )\n",
    "        model.restore()\n",
    "        #Sample stuff\n",
    "        print('>>>>> {}'.format(start_seed), RNNTextGenerator.sample(\n",
    "            model,\n",
    "            dataset,\n",
    "            start_seed,\n",
    "            50\n",
    "        ))\n",
    "        print('<<<<<<')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test(dataset = dataset, learning_rate = learning_rate, start_seed = \".\\n\", model_name = \"boo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
